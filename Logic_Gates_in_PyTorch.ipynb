{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Logic Gates in PyT:fire:rch\n",
    "\n",
    "Only for **XOR**, **OR**, and **AND**! [Here](https://www.elprocus.com/basic-logic-gates-with-truth-tables/) are some simple and good explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: white; display: fill; border-radius: 5px; background-color: #6905ed; font-size: 110%\">\n",
    "  <h2 style=\"padding: 15px; color: white;\">Using Predefined Functions</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.tensor([0, 0, 1, 1], dtype=torch.int8)\n",
    "data2 = torch.tensor([0, 1, 0, 1], dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True, False])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logical_xor(data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logical_or(data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logical_and(data1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: white; display: fill; border-radius: 5px; background-color: #f55925; font-size: 110%\">\n",
    "  <h2 style=\"padding: 15px; color: white;\">Logistic Regression and the Module Class</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Feeds the data to the neural network.\"\"\"\n",
    "        output = torch.sigmoid(self.linear1(x))\n",
    "        output = torch.sigmoid(self.linear2(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: Union[nn.Module, nn.Sequential], criterion: Union[nn.MSELoss, nn.BCELoss],\n",
    "          optimizer: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "          X: torch.Tensor, y: torch.Tensor, epochs: int) -> None:\n",
    "    \"\"\"Trains the neural network and reports.\"\"\"\n",
    "    epochs_size = len(str(epochs))  # To beautify when reporting\n",
    "    \n",
    "    for epoch in range(epochs+1):\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print the loss in every 5% of epochs\n",
    "        if epoch % int(epochs * .05) == 0:\n",
    "            print(f'[EPOCH {epoch: >{epochs_size}}/{epochs}] The loss is {loss.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding type annotations to PyTorch is painful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40000\n",
    "input_dim = 2\n",
    "hidden_dim = 3\n",
    "output_dim = 1\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logical_xor = LogisticRegression(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_logical_xor.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH     0/40000] The loss is 0.24826\n",
      "[EPOCH  2000/40000] The loss is 0.24794\n",
      "[EPOCH  4000/40000] The loss is 0.24753\n",
      "[EPOCH  6000/40000] The loss is 0.24701\n",
      "[EPOCH  8000/40000] The loss is 0.24635\n",
      "[EPOCH 10000/40000] The loss is 0.24549\n",
      "[EPOCH 12000/40000] The loss is 0.24436\n",
      "[EPOCH 14000/40000] The loss is 0.24287\n",
      "[EPOCH 16000/40000] The loss is 0.24089\n",
      "[EPOCH 18000/40000] The loss is 0.23824\n",
      "[EPOCH 20000/40000] The loss is 0.23468\n",
      "[EPOCH 22000/40000] The loss is 0.22991\n",
      "[EPOCH 24000/40000] The loss is 0.22357\n",
      "[EPOCH 26000/40000] The loss is 0.21522\n",
      "[EPOCH 28000/40000] The loss is 0.20437\n",
      "[EPOCH 30000/40000] The loss is 0.19059\n",
      "[EPOCH 32000/40000] The loss is 0.17375\n",
      "[EPOCH 34000/40000] The loss is 0.15429\n",
      "[EPOCH 36000/40000] The loss is 0.13344\n",
      "[EPOCH 38000/40000] The loss is 0.11291\n",
      "[EPOCH 40000/40000] The loss is 0.09425\n"
     ]
    }
   ],
   "source": [
    "train(model_logical_xor, criterion, optimizer, X, y, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logical_xor(X) \\\n",
    "    .round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logical_or = LogisticRegression(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_logical_or.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [1], [1], [1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH     0/40000] The loss is 0.33582\n",
      "[EPOCH  2000/40000] The loss is 0.17480\n",
      "[EPOCH  4000/40000] The loss is 0.16493\n",
      "[EPOCH  6000/40000] The loss is 0.15142\n",
      "[EPOCH  8000/40000] The loss is 0.13335\n",
      "[EPOCH 10000/40000] The loss is 0.11128\n",
      "[EPOCH 12000/40000] The loss is 0.08790\n",
      "[EPOCH 14000/40000] The loss is 0.06676\n",
      "[EPOCH 16000/40000] The loss is 0.04997\n",
      "[EPOCH 18000/40000] The loss is 0.03765\n",
      "[EPOCH 20000/40000] The loss is 0.02891\n",
      "[EPOCH 22000/40000] The loss is 0.02274\n",
      "[EPOCH 24000/40000] The loss is 0.01831\n",
      "[EPOCH 26000/40000] The loss is 0.01506\n",
      "[EPOCH 28000/40000] The loss is 0.01264\n",
      "[EPOCH 30000/40000] The loss is 0.01078\n",
      "[EPOCH 32000/40000] The loss is 0.00933\n",
      "[EPOCH 34000/40000] The loss is 0.00817\n",
      "[EPOCH 36000/40000] The loss is 0.00724\n",
      "[EPOCH 38000/40000] The loss is 0.00647\n",
      "[EPOCH 40000/40000] The loss is 0.00584\n"
     ]
    }
   ],
   "source": [
    "train(model_logical_or, criterion, optimizer, X, y, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logical_or(X) \\\n",
    "    .round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logical_and = LogisticRegression(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_logical_and.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH     0/40000] The loss is 0.32067\n",
      "[EPOCH  2000/40000] The loss is 0.18755\n",
      "[EPOCH  4000/40000] The loss is 0.18151\n",
      "[EPOCH  6000/40000] The loss is 0.17368\n",
      "[EPOCH  8000/40000] The loss is 0.16387\n",
      "[EPOCH 10000/40000] The loss is 0.15249\n",
      "[EPOCH 12000/40000] The loss is 0.13986\n",
      "[EPOCH 14000/40000] The loss is 0.12625\n",
      "[EPOCH 16000/40000] The loss is 0.11209\n",
      "[EPOCH 18000/40000] The loss is 0.09789\n",
      "[EPOCH 20000/40000] The loss is 0.08423\n",
      "[EPOCH 22000/40000] The loss is 0.07165\n",
      "[EPOCH 24000/40000] The loss is 0.06054\n",
      "[EPOCH 26000/40000] The loss is 0.05104\n",
      "[EPOCH 28000/40000] The loss is 0.04313\n",
      "[EPOCH 30000/40000] The loss is 0.03662\n",
      "[EPOCH 32000/40000] The loss is 0.03131\n",
      "[EPOCH 34000/40000] The loss is 0.02699\n",
      "[EPOCH 36000/40000] The loss is 0.02346\n",
      "[EPOCH 38000/40000] The loss is 0.02056\n",
      "[EPOCH 40000/40000] The loss is 0.01817\n"
     ]
    }
   ],
   "source": [
    "train(model_logical_and, criterion, optimizer, X, y, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logical_and(X) \\\n",
    "    .round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
