{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Evaluation\n",
    "\n",
    "This data set is composed of 1728 records and 6 different attributes which are buying price, price of maintenance, number of doors, capacity in terms of persons to carry, the relative size of luggage boot and the estimated safety value of each car. There is no missing value in the data set as a big advantage you may directly dive into developing your algorithm without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly flaml\\[notebook] auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheikhartin/.local/lib/python3.9/site-packages/flaml/searcher/blendsearch.py:14: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\n",
      "  from ray.tune.suggest import Searcher\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/flaml/searcher/blendsearch.py:15: DeprecationWarning: The module `ray.tune.suggest.optuna` has been moved to `ray.tune.search.optuna` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.optuna` with `ray.tune.search.optuna`.\n",
      "  from ray.tune.suggest.optuna import OptunaSearch as GlobalSearch\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/flaml/tune/__init__.py:5: DeprecationWarning: The module `ray.tune.sample` has been moved to `ray.tune.search.sample` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.sample` with `ray.tune.search.sample`.\n",
      "  from ray.tune import (\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/flaml/tune/space.py:6: DeprecationWarning: The module `ray.tune.suggest.variant_generator` has been moved to `ray.tune.search.variant_generator` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest.variant_generator` with `ray.tune.search.variant_generator`.\n",
      "  from ray.tune.suggest.variant_generator import generate_variants\n"
     ]
    }
   ],
   "source": [
    "# Built-in libraries\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from flaml import AutoML\n",
    "from autosklearn.classification import AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/titanic.csv\n",
      "datasets/car_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "for path in Path('./datasets').rglob('*'):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/car_evaluation.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    0: 'buying',\n",
    "    1: 'maint',\n",
    "    2: 'doors',\n",
    "    3: 'persons',\n",
    "    4: 'lug_boot',\n",
    "    5: 'safety',\n",
    "    6: 'class',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      " 6   class     1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying  maint doors persons lug_boot safety  class\n",
       "count    1728   1728  1728    1728     1728   1728   1728\n",
       "unique      4      4     4       3        3      3      4\n",
       "top     vhigh  vhigh     2       2    small    low  unacc\n",
       "freq      432    432   432     576      576    576   1210"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No correlation was found due to the non-numerical nature of our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">buying</th>\n",
       "      <th colspan=\"3\" halign=\"left\">maint</th>\n",
       "      <th colspan=\"3\" halign=\"left\">doors</th>\n",
       "      <th colspan=\"3\" halign=\"left\">persons</th>\n",
       "      <th colspan=\"3\" halign=\"left\">lug_boot</th>\n",
       "      <th colspan=\"3\" halign=\"left\">safety</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>384</td>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>384</td>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>384</td>\n",
       "      <td>2</td>\n",
       "      <td>5more</td>\n",
       "      <td>384</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>384</td>\n",
       "      <td>big</td>\n",
       "      <td>small</td>\n",
       "      <td>384</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>69</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>69</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>5more</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>69</td>\n",
       "      <td>big</td>\n",
       "      <td>small</td>\n",
       "      <td>69</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacc</th>\n",
       "      <td>1210</td>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>1210</td>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "      <td>5more</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>1210</td>\n",
       "      <td>big</td>\n",
       "      <td>small</td>\n",
       "      <td>1210</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgood</th>\n",
       "      <td>65</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>65</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>5more</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>65</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>65</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying              maint              doors            persons      \\\n",
       "       count   min    max count   min    max count min    max   count min   \n",
       "class                                                                       \n",
       "acc      384  high  vhigh   384  high  vhigh   384   2  5more     384   4   \n",
       "good      69   low    med    69   low    med    69   2  5more      69   4   \n",
       "unacc   1210  high  vhigh  1210  high  vhigh  1210   2  5more    1210   2   \n",
       "vgood     65   low    med    65  high    med    65   2  5more      65   4   \n",
       "\n",
       "            lug_boot             safety              \n",
       "        max    count  min    max  count   min   max  \n",
       "class                                                \n",
       "acc    more      384  big  small    384  high   med  \n",
       "good   more       69  big  small     69  high   med  \n",
       "unacc  more     1210  big  small   1210  high   med  \n",
       "vgood  more       65  big    med     65  high  high  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['class']).agg({\n",
    "    'buying': ['count', 'min', 'max'],\n",
    "    'maint': ['count', 'min', 'max'],\n",
    "    'doors': ['count', 'min', 'max'],\n",
    "    'persons': ['count', 'min', 'max'],\n",
    "    'lug_boot': ['count', 'min', 'max'],\n",
    "    'safety': ['count', 'min', 'max'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nonsense grouping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "safety=low<br>class=%{x}<br>buying=%{y}<extra></extra>",
         "legendgroup": "low",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "low",
         "offsetgroup": "low",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc"
         ],
         "xaxis": "x",
         "y": [
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "safety=med<br>class=%{x}<br>buying=%{y}<extra></extra>",
         "legendgroup": "med",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "med",
         "offsetgroup": "med",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "good",
          "unacc",
          "acc",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "good",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "good",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "good",
          "unacc",
          "acc",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "good",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "good",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "good",
          "unacc",
          "acc",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "good",
          "good",
          "acc",
          "good",
          "good",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "good",
          "good",
          "acc",
          "good",
          "good"
         ],
         "xaxis": "x",
         "y": [
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "safety=high<br>class=%{x}<br>buying=%{y}<extra></extra>",
         "legendgroup": "high",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "high",
         "offsetgroup": "high",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "vgood",
          "unacc",
          "acc",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "vgood",
          "acc",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "vgood",
          "vgood",
          "acc",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "vgood",
          "vgood",
          "acc",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "good",
          "vgood",
          "unacc",
          "good",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "good",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "vgood",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "vgood",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "acc",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "vgood",
          "unacc",
          "acc",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "acc",
          "vgood",
          "acc",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "vgood",
          "vgood",
          "acc",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "acc",
          "vgood",
          "vgood",
          "acc",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "good",
          "vgood",
          "unacc",
          "good",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "good",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "vgood",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "vgood",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "good",
          "vgood",
          "unacc",
          "good",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "good",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "vgood",
          "vgood",
          "good",
          "vgood",
          "vgood",
          "unacc",
          "unacc",
          "unacc",
          "good",
          "vgood",
          "vgood",
          "good",
          "vgood",
          "vgood"
         ],
         "xaxis": "x",
         "y": [
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "vhigh",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "high",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "med",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low",
          "low"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "safety"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Is There Any Relationship Between the Safety of the Car and Its Price?"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "class"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "buying"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(data_frame=df, x='class', y='buying', color='safety',\n",
    "       title='Is There Any Relationship Between the Safety of the Car and Its Price?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this moment, I don't know much about how to plot categorical data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['buying'] = le.fit_transform(df['buying'])\n",
    "df['maint'] = le.fit_transform(df['maint'])\n",
    "df['doors'] = le.fit_transform(df['doors'])\n",
    "df['persons'] = le.fit_transform(df['persons'])\n",
    "df['lug_boot'] = le.fit_transform(df['lug_boot'])\n",
    "df['safety'] = le.fit_transform(df['safety'])\n",
    "df['class'] = le.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations after encoding the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "buying",
          "maint",
          "doors",
          "persons",
          "lug_boot",
          "safety",
          "class"
         ],
         "xaxis": "x",
         "y": [
          "buying",
          "maint",
          "doors",
          "persons",
          "lug_boot",
          "safety",
          "class"
         ],
         "yaxis": "y",
         "z": [
          [
           1.0000000000000002,
           7.709882115452475e-19,
           5.725872451076039e-17,
           5.194137910916931e-17,
           4.159533205083886e-17,
           0,
           0.05142422396992501
          ],
          [
           7.709882115452475e-19,
           0.9999999999999991,
           -5.139921410301648e-19,
           9.431090515757025e-18,
           5.440472364686704e-17,
           0,
           0.04019364632132081
          ],
          [
           5.725872451076039e-17,
           -5.139921410301648e-19,
           0.9999999999999998,
           2.815250900225979e-19,
           5.4052817284338805e-17,
           0,
           -0.03132740080926471
          ],
          [
           5.194137910916931e-17,
           9.431090515757025e-18,
           2.815250900225979e-19,
           0.9999999999999988,
           7.401486830834372e-17,
           0,
           -0.29946829781880885
          ],
          [
           4.159533205083886e-17,
           5.440472364686704e-17,
           5.4052817284338805e-17,
           7.401486830834372e-17,
           0.9999999999999996,
           0,
           0.03318432489343477
          ],
          [
           0,
           0,
           0,
           0,
           0,
           1.0000000000000002,
           -0.02104371822510674
          ],
          [
           0.05142422396992501,
           0.04019364632132081,
           -0.03132740080926471,
           -0.29946829781880885,
           0.03318432489343477,
           -0.02104371822510674,
           1.000000000000006
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.imshow(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1382, 6), (1382,), (346, 6), (346,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "y = df['safety']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use two different AutoML frameworks to figure out our best model in this dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first framework is `FLAML` by Microsoft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheikhartin/.local/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator SimpleImputer from version 1.1.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator ColumnTransformer from version 1.1.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator LabelEncoder from version 1.1.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator DecisionTreeClassifier from version 1.1.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator RandomForestClassifier from version 1.1.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML(append_log=False, auto_augment=True, custom_hp={}, early_stop=False,\n",
       "       ensemble=False, estimator_list='auto', eval_method='auto',\n",
       "       fit_kwargs_by_estimator={}, hpo_method='auto', keep_search_state=False,\n",
       "       learner_selector='sample', log_file_name='', log_training_metric=False,\n",
       "       log_type='better', max_iter=None, mem_thres=4294967296, metric='auto',\n",
       "       metric_constraints=[], min_sample_size=10000, model_history=False,\n",
       "       n_concurrent_trials=1, n_jobs=-1, n_splits=5, pred_time_limit=inf,\n",
       "       retrain_full=True, sample=True, split_ratio=0.1, split_type='auto',\n",
       "       starting_points='static', task='classification', ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./exports/car_evaluation_flaml_model.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-05 21:47:56] {2565} INFO - task = classification\n",
      "[flaml.automl: 09-05 21:47:56] {2567} INFO - Data split method: stratified\n",
      "[flaml.automl: 09-05 21:47:56] {2570} INFO - Evaluation method: cv\n",
      "[flaml.automl: 09-05 21:47:56] {2689} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl: 09-05 21:47:56] {2831} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 09-05 21:47:56] {3133} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3266} INFO - Estimated sufficient time budget=12698s. Estimated necessary time budget=312s.\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.3s,\testimator lgbm's best error=0.9100,\tbest estimator lgbm's best error=0.9100\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.4s,\testimator lgbm's best error=0.9100,\tbest estimator lgbm's best error=0.9100\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.5s,\testimator lgbm's best error=0.6434,\tbest estimator lgbm's best error=0.6434\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.6s,\testimator lgbm's best error=0.2063,\tbest estimator lgbm's best error=0.2063\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.6s,\testimator lgbm's best error=0.2063,\tbest estimator lgbm's best error=0.2063\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.7s,\testimator lgbm's best error=0.1867,\tbest estimator lgbm's best error=0.1867\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:57] {3313} INFO -  at 1.8s,\testimator lgbm's best error=0.1867,\tbest estimator lgbm's best error=0.1867\n",
      "[flaml.automl: 09-05 21:47:57] {3133} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 1.9s,\testimator lgbm's best error=0.0954,\tbest estimator lgbm's best error=0.0954\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.0s,\testimator lgbm's best error=0.0954,\tbest estimator lgbm's best error=0.0954\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.1s,\testimator lgbm's best error=0.0954,\tbest estimator lgbm's best error=0.0954\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.2s,\testimator lgbm's best error=0.0954,\tbest estimator lgbm's best error=0.0954\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.2s,\testimator lgbm's best error=0.0950,\tbest estimator lgbm's best error=0.0950\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.4s,\testimator lgbm's best error=0.0950,\tbest estimator lgbm's best error=0.0950\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.4s,\testimator lgbm's best error=0.0950,\tbest estimator lgbm's best error=0.0950\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.5s,\testimator lgbm's best error=0.0950,\tbest estimator lgbm's best error=0.0950\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:58] {3313} INFO -  at 2.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:58] {3133} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 2.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 2.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 09-05 21:47:59] {3313} INFO -  at 3.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:47:59] {3133} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 3.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 3.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:00] {3313} INFO -  at 4.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:00] {3133} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 4.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 4.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 4.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 4.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:01] {3313} INFO -  at 5.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:01] {3133} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 5.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 72, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 5.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 5.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.2s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 82, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 84, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:02] {3313} INFO -  at 6.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:02] {3133} INFO - iteration 91, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 6.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 6.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 6.9s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 7.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 7.0s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 7.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:03] {3313} INFO -  at 7.7s,\testimator xgboost's best error=0.9551,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:03] {3133} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.0s,\testimator xgboost's best error=0.9551,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.2s,\testimator xgboost's best error=0.7500,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.4s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.5s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:04] {3313} INFO -  at 8.7s,\testimator xgboost's best error=0.1920,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:04] {3133} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:05] {3313} INFO -  at 9.0s,\testimator xgboost's best error=0.1920,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:05] {3133} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:05] {3313} INFO -  at 9.3s,\testimator xgboost's best error=0.1920,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:05] {3133} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 09-05 21:48:05] {3313} INFO -  at 9.5s,\testimator xgboost's best error=0.1916,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:05] {3133} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:05] {3313} INFO -  at 9.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:05] {3133} INFO - iteration 109, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:05] {3313} INFO -  at 9.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:05] {3133} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:05] {3313} INFO -  at 9.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:05] {3133} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.0s,\testimator extra_tree's best error=0.5584,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.2s,\testimator extra_tree's best error=0.2801,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.3s,\testimator extra_tree's best error=0.2801,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.3s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 115, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.5s,\testimator extra_tree's best error=0.2801,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 116, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.7s,\testimator extra_tree's best error=0.1850,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:06] {3313} INFO -  at 10.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:06] {3133} INFO - iteration 118, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 10.9s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.1s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.3s,\testimator rf's best error=0.4612,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 121, current learner rf\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.4s,\testimator rf's best error=0.2621,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 122, current learner rf\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.6s,\testimator rf's best error=0.2621,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.6s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.7s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:07] {3313} INFO -  at 11.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:07] {3133} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:08] {3313} INFO -  at 11.8s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:08] {3133} INFO - iteration 127, current learner rf\n",
      "[flaml.automl: 09-05 21:48:08] {3313} INFO -  at 12.0s,\testimator rf's best error=0.2621,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:08] {3133} INFO - iteration 128, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:08] {3313} INFO -  at 12.4s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:08] {3133} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 09-05 21:48:08] {3313} INFO -  at 12.6s,\testimator rf's best error=0.1765,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:08] {3133} INFO - iteration 130, current learner rf\n",
      "[flaml.automl: 09-05 21:48:09] {3313} INFO -  at 12.8s,\testimator rf's best error=0.1765,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:09] {3133} INFO - iteration 131, current learner rf\n",
      "[flaml.automl: 09-05 21:48:09] {3313} INFO -  at 13.0s,\testimator rf's best error=0.1386,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:09] {3133} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl: 09-05 21:48:09] {3313} INFO -  at 13.1s,\testimator lgbm's best error=0.0949,\tbest estimator lgbm's best error=0.0949\n",
      "[flaml.automl: 09-05 21:48:09] {3133} INFO - iteration 133, current learner rf\n",
      "[flaml.automl: 09-05 21:48:09] {3313} INFO -  at 13.4s,\testimator rf's best error=0.0647,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:09] {3133} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 09-05 21:48:09] {3313} INFO -  at 13.5s,\testimator rf's best error=0.0647,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:09] {3133} INFO - iteration 135, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:09] {3313} INFO -  at 13.7s,\testimator extra_tree's best error=0.1234,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:09] {3133} INFO - iteration 136, current learner rf\n",
      "[flaml.automl: 09-05 21:48:10] {3313} INFO -  at 14.0s,\testimator rf's best error=0.0647,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:10] {3133} INFO - iteration 137, current learner rf\n",
      "[flaml.automl: 09-05 21:48:10] {3313} INFO -  at 14.3s,\testimator rf's best error=0.0647,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:10] {3133} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:10] {3313} INFO -  at 14.5s,\testimator extra_tree's best error=0.1234,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:10] {3133} INFO - iteration 139, current learner rf\n",
      "[flaml.automl: 09-05 21:48:10] {3313} INFO -  at 14.7s,\testimator rf's best error=0.0647,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:10] {3133} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:11] {3313} INFO -  at 14.9s,\testimator extra_tree's best error=0.1234,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:11] {3133} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 09-05 21:48:11] {3313} INFO -  at 15.3s,\testimator rf's best error=0.0647,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:11] {3133} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:11] {3313} INFO -  at 15.4s,\testimator extra_tree's best error=0.1234,\tbest estimator rf's best error=0.0647\n",
      "[flaml.automl: 09-05 21:48:11] {3133} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:11] {3313} INFO -  at 15.6s,\testimator extra_tree's best error=0.0151,\tbest estimator extra_tree's best error=0.0151\n",
      "[flaml.automl: 09-05 21:48:11] {3133} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:11] {3313} INFO -  at 15.8s,\testimator extra_tree's best error=0.0151,\tbest estimator extra_tree's best error=0.0151\n",
      "[flaml.automl: 09-05 21:48:11] {3133} INFO - iteration 145, current learner rf\n",
      "[flaml.automl: 09-05 21:48:12] {3313} INFO -  at 15.9s,\testimator rf's best error=0.0157,\tbest estimator extra_tree's best error=0.0151\n",
      "[flaml.automl: 09-05 21:48:12] {3133} INFO - iteration 146, current learner rf\n",
      "[flaml.automl: 09-05 21:48:12] {3313} INFO -  at 16.3s,\testimator rf's best error=0.0157,\tbest estimator extra_tree's best error=0.0151\n",
      "[flaml.automl: 09-05 21:48:12] {3133} INFO - iteration 147, current learner rf\n",
      "[flaml.automl: 09-05 21:48:12] {3313} INFO -  at 16.5s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
      "[flaml.automl: 09-05 21:48:12] {3133} INFO - iteration 148, current learner rf\n",
      "[flaml.automl: 09-05 21:48:12] {3313} INFO -  at 16.7s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
      "[flaml.automl: 09-05 21:48:12] {3133} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 09-05 21:48:13] {3313} INFO -  at 16.9s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
      "[flaml.automl: 09-05 21:48:13] {3133} INFO - iteration 150, current learner rf\n",
      "[flaml.automl: 09-05 21:48:13] {3313} INFO -  at 17.1s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:13] {3133} INFO - iteration 151, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:13] {3313} INFO -  at 17.5s,\testimator extra_tree's best error=0.0151,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:13] {3133} INFO - iteration 152, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:13] {3313} INFO -  at 17.6s,\testimator extra_tree's best error=0.0008,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:13] {3133} INFO - iteration 153, current learner rf\n",
      "[flaml.automl: 09-05 21:48:14] {3313} INFO -  at 17.9s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:14] {3133} INFO - iteration 154, current learner rf\n",
      "[flaml.automl: 09-05 21:48:14] {3313} INFO -  at 18.1s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:14] {3133} INFO - iteration 155, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:14] {3313} INFO -  at 18.3s,\testimator extra_tree's best error=0.0008,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:14] {3133} INFO - iteration 156, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:14] {3313} INFO -  at 18.5s,\testimator extra_tree's best error=0.0008,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:14] {3133} INFO - iteration 157, current learner rf\n",
      "[flaml.automl: 09-05 21:48:14] {3313} INFO -  at 18.7s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:14] {3133} INFO - iteration 158, current learner rf\n",
      "[flaml.automl: 09-05 21:48:15] {3313} INFO -  at 19.0s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:15] {3133} INFO - iteration 159, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:15] {3313} INFO -  at 19.3s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:15] {3133} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 09-05 21:48:15] {3313} INFO -  at 19.7s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:15] {3133} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:16] {3313} INFO -  at 19.9s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:16] {3133} INFO - iteration 162, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:16] {3313} INFO -  at 20.2s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:16] {3133} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:16] {3313} INFO -  at 20.4s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:16] {3133} INFO - iteration 164, current learner rf\n",
      "[flaml.automl: 09-05 21:48:16] {3313} INFO -  at 20.6s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:16] {3133} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:17] {3313} INFO -  at 20.9s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:17] {3133} INFO - iteration 166, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:17] {3313} INFO -  at 21.3s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:17] {3133} INFO - iteration 167, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:17] {3313} INFO -  at 21.5s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:17] {3133} INFO - iteration 168, current learner rf\n",
      "[flaml.automl: 09-05 21:48:17] {3313} INFO -  at 21.7s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:17] {3133} INFO - iteration 169, current learner rf\n",
      "[flaml.automl: 09-05 21:48:18] {3313} INFO -  at 21.9s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:18] {3133} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 09-05 21:48:18] {3313} INFO -  at 22.2s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:18] {3133} INFO - iteration 171, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:18] {3313} INFO -  at 22.5s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:18] {3133} INFO - iteration 172, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:18] {3313} INFO -  at 22.7s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:18] {3133} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:19] {3313} INFO -  at 23.0s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:19] {3133} INFO - iteration 174, current learner rf\n",
      "[flaml.automl: 09-05 21:48:19] {3313} INFO -  at 23.2s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:19] {3133} INFO - iteration 175, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:19] {3313} INFO -  at 23.4s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:19] {3133} INFO - iteration 176, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:19] {3313} INFO -  at 23.6s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:19] {3133} INFO - iteration 177, current learner rf\n",
      "[flaml.automl: 09-05 21:48:20] {3313} INFO -  at 23.8s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:20] {3133} INFO - iteration 178, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:20] {3313} INFO -  at 24.1s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:20] {3133} INFO - iteration 179, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:20] {3313} INFO -  at 24.4s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:20] {3133} INFO - iteration 180, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:20] {3313} INFO -  at 24.5s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:20] {3133} INFO - iteration 181, current learner rf\n",
      "[flaml.automl: 09-05 21:48:21] {3313} INFO -  at 24.8s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:21] {3133} INFO - iteration 182, current learner rf\n",
      "[flaml.automl: 09-05 21:48:21] {3313} INFO -  at 25.1s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:21] {3133} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 09-05 21:48:21] {3313} INFO -  at 25.3s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:21] {3133} INFO - iteration 184, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:21] {3313} INFO -  at 25.4s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:21] {3133} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 09-05 21:48:21] {3313} INFO -  at 25.6s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:21] {3133} INFO - iteration 186, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:22] {3313} INFO -  at 25.9s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:22] {3133} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 09-05 21:48:22] {3313} INFO -  at 26.2s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:22] {3133} INFO - iteration 188, current learner rf\n",
      "[flaml.automl: 09-05 21:48:22] {3313} INFO -  at 26.5s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:22] {3133} INFO - iteration 189, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:23] {3313} INFO -  at 26.9s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:23] {3133} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 09-05 21:48:23] {3313} INFO -  at 27.0s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:23] {3133} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:23] {3313} INFO -  at 27.2s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:23] {3133} INFO - iteration 192, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:23] {3313} INFO -  at 27.4s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:23] {3133} INFO - iteration 193, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:23] {3313} INFO -  at 27.6s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:23] {3133} INFO - iteration 194, current learner rf\n",
      "[flaml.automl: 09-05 21:48:24] {3313} INFO -  at 27.8s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:24] {3133} INFO - iteration 195, current learner rf\n",
      "[flaml.automl: 09-05 21:48:24] {3313} INFO -  at 28.1s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:24] {3133} INFO - iteration 196, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:24] {3313} INFO -  at 28.4s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:24] {3133} INFO - iteration 197, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:24] {3313} INFO -  at 28.6s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:24] {3133} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:25] {3313} INFO -  at 28.8s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:25] {3133} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:25] {3313} INFO -  at 29.0s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:25] {3133} INFO - iteration 200, current learner rf\n",
      "[flaml.automl: 09-05 21:48:25] {3313} INFO -  at 29.3s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:25] {3133} INFO - iteration 201, current learner rf\n",
      "[flaml.automl: 09-05 21:48:25] {3313} INFO -  at 29.5s,\testimator rf's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:25] {3133} INFO - iteration 202, current learner extra_tree\n",
      "[flaml.automl: 09-05 21:48:25] {3313} INFO -  at 29.8s,\testimator extra_tree's best error=0.0000,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:25] {3133} INFO - iteration 203, current learner catboost\n",
      "[flaml.automl: 09-05 21:48:27] {3313} INFO -  at 30.9s,\testimator catboost's best error=0.9528,\tbest estimator rf's best error=0.0000\n",
      "[flaml.automl: 09-05 21:48:27] {3577} INFO - retrain rf for 0.1s\n",
      "[flaml.automl: 09-05 21:48:27] {3584} INFO - retrained model: RandomForestClassifier(criterion='entropy', max_features=0.859364268853592,\n",
      "                       max_leaf_nodes=49, n_estimators=7, n_jobs=-1)\n",
      "[flaml.automl: 09-05 21:48:27] {2862} INFO - fit succeeded\n",
      "[flaml.automl: 09-05 21:48:27] {2863} INFO - Time taken to find the best model: 17.118199110031128\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task='classification', time_budget=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=0.859364268853592,\n",
       "                       max_leaf_nodes=49, n_estimators=7, n_jobs=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 1, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 2, 1, 1,\n",
       "       0, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 0, 1, 2,\n",
       "       1, 0, 2, 0, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 1,\n",
       "       0, 2, 0, 0, 1, 1, 2, 0, 1, 2, 0, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2,\n",
       "       1, 1, 2, 1, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 2, 2, 0,\n",
       "       2, 1, 1, 1, 1, 1, 1, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 1, 1, 0, 2, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1,\n",
       "       2, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 2, 1,\n",
       "       2, 1, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 0,\n",
       "       2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 2, 2, 1, 0, 1, 1, 0, 2, 2,\n",
       "       1, 2, 2, 1, 2, 0, 1, 1, 0, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 0, 0, 2, 2, 1,\n",
       "       2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 2, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00       102\n",
      "           2       1.00      1.00      1.00       122\n",
      "\n",
      "    accuracy                           1.00       346\n",
      "   macro avg       1.00      1.00      1.00       346\n",
      "weighted avg       1.00      1.00      1.00       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./exports/car_evaluation_flaml_model.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to do it with `Auto-Sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(per_run_time_limit=6, time_left_for_this_task=60)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./exports/car_evaluation_autosklearn_model.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)\n",
    "automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheikhartin/.local/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "/home/sheikhartin/.local/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(per_run_time_limit=6, time_left_for_this_task=60)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = AutoSklearnClassifier(time_left_for_this_task=60)\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>ensemble_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>cost</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.281472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>passive_aggressive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.883725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.171730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.686456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>gaussian_nb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.047975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rank  ensemble_weight                type  cost  duration\n",
       "model_id                                                           \n",
       "2            1             0.20       random_forest   0.0  4.281472\n",
       "3            2             0.28  passive_aggressive   0.0  3.883725\n",
       "4            3             0.12       random_forest   0.0  5.171730\n",
       "5            4             0.16       random_forest   0.0  4.686456\n",
       "12           5             0.24         gaussian_nb   0.0  2.047975"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'model_id': 2,\n",
       "  'rank': 1,\n",
       "  'cost': 0.0,\n",
       "  'ensemble_weight': 0.2,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7fc7a8a61340>,\n",
       "  'balancing': Balancing(random_state=1),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7fc7afa65ee0>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7fc7b066edf0>,\n",
       "  'sklearn_classifier': RandomForestClassifier(max_features=2, n_estimators=512, n_jobs=1,\n",
       "                         random_state=1, warm_start=True)},\n",
       " 3: {'model_id': 3,\n",
       "  'rank': 2,\n",
       "  'cost': 0.0,\n",
       "  'ensemble_weight': 0.28,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7fc7a8b8d670>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7fc7a8b8ba60>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7fc7a8b8be50>,\n",
       "  'sklearn_classifier': PassiveAggressiveClassifier(C=2.6029223727861803e-05, loss='squared_hinge',\n",
       "                              max_iter=512, random_state=1,\n",
       "                              tol=4.631073253805713e-05, warm_start=True)},\n",
       " 4: {'model_id': 4,\n",
       "  'rank': 3,\n",
       "  'cost': 0.0,\n",
       "  'ensemble_weight': 0.12,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7fc7a89a22e0>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7fc7a8948d30>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7fc7a8b9b0d0>,\n",
       "  'sklearn_classifier': RandomForestClassifier(max_features=1, min_samples_split=6, n_estimators=512,\n",
       "                         n_jobs=1, random_state=1, warm_start=True)},\n",
       " 5: {'model_id': 5,\n",
       "  'rank': 4,\n",
       "  'cost': 0.0,\n",
       "  'ensemble_weight': 0.16,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7fc7afc34bb0>,\n",
       "  'balancing': Balancing(random_state=1),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7fc7afc726a0>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7fc7afc727c0>,\n",
       "  'sklearn_classifier': RandomForestClassifier(max_features=3, min_samples_leaf=15, min_samples_split=3,\n",
       "                         n_estimators=512, n_jobs=1, random_state=1,\n",
       "                         warm_start=True)},\n",
       " 12: {'model_id': 12,\n",
       "  'rank': 5,\n",
       "  'cost': 0.0,\n",
       "  'ensemble_weight': 0.24,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7fc7a613ea90>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7fc7a612f8e0>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7fc7a612f9a0>,\n",
       "  'sklearn_classifier': GaussianNB()}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 1, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 2, 1, 1,\n",
       "       0, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 0, 1, 2,\n",
       "       1, 0, 2, 0, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 1,\n",
       "       0, 2, 0, 0, 1, 1, 2, 0, 1, 2, 0, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2,\n",
       "       1, 1, 2, 1, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 2, 2, 0,\n",
       "       2, 1, 1, 1, 1, 1, 1, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 1, 1, 0, 2, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1,\n",
       "       2, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 2, 1,\n",
       "       2, 1, 2, 0, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 0,\n",
       "       2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 2, 2, 1, 0, 1, 1, 0, 2, 2,\n",
       "       1, 2, 2, 1, 2, 0, 1, 1, 0, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 0, 0, 2, 2, 1,\n",
       "       2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 2, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00       102\n",
      "           2       1.00      1.00      1.00       122\n",
      "\n",
      "    accuracy                           1.00       346\n",
      "   macro avg       1.00      1.00      1.00       346\n",
      "weighted avg       1.00      1.00      1.00       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./exports/car_evaluation_autosklearn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
